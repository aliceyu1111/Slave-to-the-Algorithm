# Week 1

Having absolutely zero knowledge of the coding world, I’m actually really excited into developing my understanding of the processes involved and hopefully through this studio will alter the way I think about digital design and how it can be incorporated into my future artworks.  

During class time, Karen mentioned the terms generative and parametric design, which were completing foreign words to me. So, I decided to do some further reading on these terms to further strengthen my understanding. It quickly became quite clear that the dominate industries who use generative and parametric design to their advantage are engineering and architectural designers.  

**Generative Design**: When an individual creates a set of parameters (size, weight, height, strength) into a generative design program, in which the algorithms will create the optimal solutions that would have otherwise been impossible for the human mind to curate. From these solutions, it is up to the designers to further filter and alter the parameters until a suitable solution is generated.  

For engineers, this technology method allows them to no longer be constrained by their imaginations or previous experiences. They are able to collaborate with the technology to produce new ideas that in the long run benefit the environment as well as reducing cost and increase in productivity and production.  

In summary generative design is “thinking about designing not the object – but a process to generate objects” - Michael Hansmeyer 

**Parametric Design**: Similar to generative design it requires a designer to calculate specific parameters such as materials, site constraints as well as environmental factors. However parametric design allows designers to alter projects in real-time, which allows designers to seek multiple options before making the final cut.  

**So, what's the difference between the two?** 

Reading from Karen’s notes, to me this makes the most sense. “parametric design is dependent on variables that alter the geometry or other factors (like a template), while generative design creates new objects or visuals where there were not any before (as if you are growing something


### Class Activity 1: Roll The Dice 

The results of this challenge for me were quite interesting, in terms of how illiterate and messy it was. For some reason my dice kept on landing on the option where I had to either draw with my mouth or elbow. The results were very much distorted but kind of interesting. I guess you could say this is what happens when you try to input an algorithm that is either incorrect or too much for the computer to handle so therefore it lags and creates a jumble of messy lines.  

And, don’t even get me started on drawing with your knees option as that was just impossible! This was not due to my lack of trying, because I tried and failed multiple times. 


<img src= https://github.com/aliceyu1111/Slave-to-the-Algorithm/blob/master/Week%201/Activity%201%20-%20Roll%20The%20Dice%20Rules%20Chart.png >
<img src= https://github.com/aliceyu1111/Slave-to-the-Algorithm/blob/master/Week%201/Activity%201%20-%20Roll%20The%20Dice%20Results.png >
 
 Also, if anyone is wondering what the bottom left corner was meant to be. They were supposed to be hands, but the dice landed twice on drawing hands with my mouth. 
 
 ### Artist Research
 
 _**Artist 1: Sougwen Chung**_
 
I really admire the fluidity of her artworks and her exploration of human and non-human collaborations which draws upon the notion around how instead of seeing ai technology replacing humans, we can and should be working alongside them instead. I think this is evident now than ever with Covid-19 as we rely and incorporate more and more of technology into our daily lives. 

<img src= https://github.com/aliceyu1111/Slave-to-the-Algorithm/blob/master/Week%201/Artist%201-%20Sougwen%20Chung.jpg >


**Artwork Reference:** https://sougwen.com/project/artefact1 

**TED Talk:** https://www.youtube.com/watch?v=q-GXV4Fd1oA 

_**Artist 2: Jon McCormack**_

One of his artwork series titled **“Morphgenesis Series”** explores the idea of biology vs technology. I find it quite interesting to see how with a computer software based on biological models of development we can create and alter the structure and form of plants through controlled digital DNA. It’s fun to see what's possible through the invention of technology that would have otherwise been impossible. Also solidifies what Karen mentioned in class of how the outcome of parametric and generative design can be anything really such as photography which is one area I never thought about until now. 

<img src= https://github.com/aliceyu1111/Slave-to-the-Algorithm/blob/master/Week%201/Artist%202%20-%20Jon%20McCormack-%20Image%201.png >
<img src= https://github.com/aliceyu1111/Slave-to-the-Algorithm/blob/master/Week%201/Artist%202%20-%20Jon%20McCormack-%20Image%202.jpg >

**Artwork Reference:** https://jonmccormack.info/artworks/morphogenesis-series/ 

_**Artist 3: Lauren Lee McCarthy**_

Her project **“The Changing Room”** where through an AI software installation, it invites audiences to browse through and select various types of emotions. Through this the technology system will create an environment matching that emotion through the use of lights, visuals, sound and text. I love how interactive this installation was and how it poses the question of the influence and power technology has over us.  It got me thinking to how much does technology control us and how susceptible are we to those changes. As technology progresses how much will it continue to control us?  

<img src= https://github.com/aliceyu1111/Slave-to-the-Algorithm/blob/master/Week%201/Artist%203%20-%20Lauren%20Lee%20McCarthy%20-%20The%20Changing%20Room.jpg >

**Artwork Reference:** https://lauren-mccarthy.com/The-Changing-Room

**Video of installation** https://player.vimeo.com/video/207014536

#### Playing around with Processing 

Here I was playing around with some of the codes from the examples in Processing. I wanted to see how much I could alter something by just simply adjusting numbers in the code. The results were very interesting and it was just a lot of fun to see the end result. Below are just some screenshots :) 

###### BEFORE

<img src= https://github.com/aliceyu1111/Slave-to-the-Algorithm/blob/master/Week%201/DepthSort%20Before.png >

###### AFTER

<img src= https://github.com/aliceyu1111/Slave-to-the-Algorithm/blob/master/Week%201/DepthSort%20After.png >
###### original code of Depth sorting example by Jakub Valtar 

###### BEFORE

<img src= https://github.com/aliceyu1111/Slave-to-the-Algorithm/blob/master/Week%201/DynamiteParticles%20Before.png >

###### AFTER

<img src= https://github.com/aliceyu1111/Slave-to-the-Algorithm/blob/master/Week%201/DynamiteParticles%20After.png >

###### original code of DynamicIntermediate Particles by unknown name within the examples section of Processing
I tried to slow down the particles and write my name hehe
